{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b61dd7adb645ba945fe660fa537a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating time window, enriching file\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    traces = spark.read.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/8-map-matching/MO_1510{day}/\")\n",
    "    traces = traces.repartition(150)\n",
    "    df_enriched = traces\\\n",
    "        .withColumn('minute_avl',F.minute(F.col(\"dt_avl\")))\\\n",
    "        .withColumn(\"15_min_partition\",F.concat(F.col(\"hour_avl\"),F.lit(\"-\"),F.floor(F.col(\"minute_avl\")/15)))\\\n",
    "        .withColumn(\"30_min_partition\",F.concat(F.col(\"hour_avl\"),F.lit(\"-\"),F.floor(F.col(\"minute_avl\")/30)))\\\n",
    "        .drop(\"hour_diff\",\"time_variation\",\"trip_id\",\"direction\",\"route_id\",\"trip_head\")\n",
    "    df_enriched.repartition(150).write.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/8-map-matching-enriched/MO_1510{day}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f04569889b458cbe790185c8bece83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Counting shapes per interval\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "\n",
    "    traces = spark.read.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/8-map-matching-enriched/MO_1510{day}/\")\n",
    "    \n",
    "    count_per_hour = traces.groupby(\"id_avl\",\"hour_avl\").agg(F.countDistinct(\"min_shape_sequence\").alias(\"count_shape\"))\n",
    "    count_per_15 = traces.groupby(\"id_avl\",\"15_min_partition\").agg(F.countDistinct(\"min_shape_sequence\").alias(\"count_shape\"))\n",
    "    count_per_30 = traces.groupby(\"id_avl\",\"30_min_partition\").agg(F.countDistinct(\"min_shape_sequence\").alias(\"count_shape\"))\n",
    "    \n",
    "    count_per_hour.write.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/statistic-count-shape/count-shape-per-hour/MO_1510{day}/\")\n",
    "    count_per_15.write.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/statistic-count-shape/count-shape-per-15/MO_1510{day}/\")\n",
    "    count_per_30.write.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/statistic-count-shape/count-shape-per-30/MO_1510{day}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279543b1e4f542d4b65c51e007ffb937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 1\n",
      "[Row(mean=42.810012568077084, min=1, max=408, stddev=25.990349758208588)]\n",
      "[1.0, 2.0, 23.0, 48.0, 63.0]\n",
      "Day 4\n",
      "[Row(mean=21.882219865676916, min=1, max=308, stddev=28.00707575225608)]\n",
      "[1.0, 1.0, 1.0, 1.0, 46.0]\n",
      "Day 5\n",
      "[Row(mean=43.142443097325376, min=1, max=401, stddev=26.094426321579146)]\n",
      "[1.0, 2.0, 23.0, 49.0, 63.0]\n",
      "Day 12\n",
      "[Row(mean=22.44026323188304, min=1, max=394, stddev=28.419014746332355)]\n",
      "[1.0, 1.0, 1.0, 2.0, 47.0]\n",
      "Day 17\n",
      "[Row(mean=30.998816168488712, min=1, max=372, stddev=29.4613007206485)]\n",
      "[1.0, 1.0, 1.0, 28.0, 57.0]\n",
      "Day 20\n",
      "[Row(mean=42.80716431707881, min=1, max=395, stddev=26.18756897707706)]\n",
      "[1.0, 2.0, 22.0, 48.0, 63.0]"
     ]
    }
   ],
   "source": [
    "# Statistics about the aggregation and shape count\n",
    "\n",
    "# Count_per_hour\n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "\n",
    "    counts_hour = spark.read.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/statistic-count-shape/count-shape-per-hour/MO_1510{day}/\")\n",
    "\n",
    "    print(\"Day\", day)\n",
    "    stats = counts_hour.agg(F.mean('count_shape').alias('mean'),\n",
    "                           F.min('count_shape').alias('min'),\n",
    "                           F.max('count_shape').alias('max'),\n",
    "                           F.stddev('count_shape').alias(\"stddev\")).collect()\n",
    "\n",
    "    print(stats)\n",
    "\n",
    "    quantiles = counts_hour.approxQuantile(\"count_shape\", [0.0625,0.125,0.25,0.5,0.75], 0.0001)\n",
    "\n",
    "    print(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4c2bc55c254594acffd4ec42179bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 1\n",
      "[Row(mean=11.637268480784863, min=1, max=118, stddev=7.877879289704797)]\n",
      "[1.0, 1.0, 3.0, 12.0, 18.0]\n",
      "Day 4\n",
      "[Row(mean=6.344709932441167, min=1, max=132, stddev=7.943601720018607)]\n",
      "[1.0, 1.0, 1.0, 1.0, 12.0]\n",
      "Day 5\n",
      "[Row(mean=11.746270213875848, min=1, max=142, stddev=7.927017643284481)]\n",
      "[1.0, 1.0, 3.0, 13.0, 18.0]\n",
      "Day 12\n",
      "[Row(mean=6.443837076035958, min=1, max=142, stddev=8.025781744439609)]\n",
      "[1.0, 1.0, 1.0, 1.0, 12.0]\n",
      "Day 17\n",
      "[Row(mean=8.601301699003407, min=1, max=138, stddev=8.444584560622992)]\n",
      "[1.0, 1.0, 1.0, 5.0, 17.0]\n",
      "Day 20\n",
      "[Row(mean=11.65199276794932, min=1, max=149, stddev=7.95421449029961)]\n",
      "[1.0, 1.0, 3.0, 13.0, 18.0]"
     ]
    }
   ],
   "source": [
    "# Statistics about the aggregation and shape count\n",
    "\n",
    "# Count_per_15\n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "\n",
    "    counts_hour = spark.read.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/statistic-count-shape/count-shape-per-15/MO_1510{day}/\")\n",
    "\n",
    "    print(\"Day\", day)\n",
    "    stats = counts_hour.agg(F.mean('count_shape').alias('mean'),\n",
    "                           F.min('count_shape').alias('min'),\n",
    "                           F.max('count_shape').alias('max'),\n",
    "                           F.stddev('count_shape').alias(\"stddev\")).collect()\n",
    "\n",
    "    print(stats)\n",
    "\n",
    "    quantiles = counts_hour.approxQuantile(\"count_shape\", [0.0625,0.125,0.25,0.5,0.75], 0.0001)\n",
    "\n",
    "    print(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976d7303f74d40c59f7114522c7e4f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 1\n",
      "[Row(mean=22.364078578110384, min=1, max=222, stddev=14.60306275962971)]\n",
      "[1.0, 1.0, 9.0, 24.0, 34.0]\n",
      "Day 4\n",
      "[Row(mean=11.722527939964897, min=1, max=224, stddev=15.189746116741423)]\n",
      "[1.0, 1.0, 1.0, 1.0, 23.0]\n",
      "Day 5\n",
      "[Row(mean=22.561173273999273, min=1, max=231, stddev=14.684584105586737)]\n",
      "[1.0, 1.0, 9.0, 25.0, 35.0]\n",
      "Day 12\n",
      "[Row(mean=11.952658394480876, min=1, max=245, stddev=15.363135443429323)]\n",
      "[1.0, 1.0, 1.0, 1.0, 24.0]\n",
      "Day 17\n",
      "[Row(mean=16.300832285957387, min=1, max=237, stddev=16.059026342115963)]\n",
      "[1.0, 1.0, 1.0, 12.0, 31.0]\n",
      "Day 20\n",
      "[Row(mean=22.37836834650238, min=1, max=229, stddev=14.74188342400134)]\n",
      "[1.0, 1.0, 9.0, 25.0, 35.0]"
     ]
    }
   ],
   "source": [
    "# Statistics about the aggregation and shape count\n",
    "\n",
    "# Count_per_30\n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "\n",
    "    counts_hour = spark.read.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/statistic-count-shape/count-shape-per-30/MO_1510{day}/\")\n",
    "\n",
    "    print(\"Day\", day)\n",
    "    stats = counts_hour.agg(F.mean('count_shape').alias('mean'),\n",
    "                           F.min('count_shape').alias('min'),\n",
    "                           F.max('count_shape').alias('max'),\n",
    "                           F.stddev('count_shape').alias(\"stddev\")).collect()\n",
    "\n",
    "    print(stats)\n",
    "\n",
    "    quantiles = counts_hour.approxQuantile(\"count_shape\", [0.0625,0.125,0.25,0.5,0.75], 0.0001)\n",
    "\n",
    "    print(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fb329240bf41a69a682b9aa1187194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filtering data based on the number of shapes\n",
    "\n",
    "# filtering 1 hour\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    counts_hour   = spark.read.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/statistic-count-shape/count-shape-per-hour/MO_1510{day}/\")\n",
    "    \n",
    "    counts_hour_to_exclude = counts_hour.filter(\"count_shape < 4\")\n",
    "    \n",
    "    traces_to_exclude = [f\"{row['id_avl']}-{row['hour_avl']}\" for row in counts_hour_to_exclude.collect()]\n",
    "    \n",
    "    traces = spark.read.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/8-map-matching-enriched/MO_1510{day}/\")\n",
    "    \n",
    "    traces_filtered = traces.withColumn(\"combined_col\", f.concat(f.col(\"id_avl\"), f.lit(\"-\"), f.col(\"hour_avl\")))\\\n",
    "                        .where((f.col(\"combined_col\").isin(traces_to_exclude) == False) & (f.col(\"min_distance\") < 2100))\n",
    "    \n",
    "    traces_filtered.repartition(150).write.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/9-one-hour-filter/MO_1510{day}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a817f83e261444d85a32c99eb801236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filtering data based on the number of shapes\n",
    "\n",
    "# filtering 30 min\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "days_to_analyze = [12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    counts_30_min   = spark.read.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/statistic-count-shape/count-shape-per-30/MO_1510{day}/\")\n",
    "        \n",
    "    counts_30_min_to_exclude = counts_30_min.filter(\"count_shape < 3\")\n",
    "    \n",
    "    traces_to_exclude = [f\"{row['id_avl']}-{row['30_min_partition']}\" for row in counts_30_min_to_exclude.collect()]\n",
    "    \n",
    "    traces = spark.read.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/8-map-matching-enriched/MO_1510{day}/\")\n",
    "    traces = traces.repartition(\"30_min_partition\")\n",
    "    \n",
    "    traces_filtered = traces.withColumn(\"combined_col\", f.concat(f.col(\"id_avl\"), f.lit(\"-\"), f.col(\"30_min_partition\")))\\\n",
    "                        .where((f.col(\"combined_col\").isin(traces_to_exclude) == False) & (f.col(\"min_distance\") < 2100))\n",
    "    \n",
    "    traces_filtered.repartition(\"30_min_partition\").write.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/9-30-min-filter/MO_1510{day}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data based on the number of shapes\n",
    "\n",
    "# filtering 15 min\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    counts_15_min = spark.read.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/statistic-count-shape/count-shape-per-15/MO_1510{day}/\")\n",
    "        \n",
    "    counts_15_min_to_exclude = counts_15_min.filter(\"count_shape == 1\")\n",
    "    \n",
    "    traces_to_exclude = [f\"{row['id_avl']}-{row['15_min_partition']}\" for row in counts_15_min_to_exclude.collect()]\n",
    "    \n",
    "    traces = spark.read.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/8-map-matching-enriched/MO_1510{day}/\")\n",
    "    \n",
    "    traces_filtered = traces.withColumn(\"combined_col\", f.concat(f.col(\"id_avl\"), f.lit(\"-\"), f.col(\"15_min_partition\")))\\\n",
    "                        .filter((f.col(\"combined_col\").isin(traces_to_exclude) == False) & (f.col(\"min_distance\") < 2100))\n",
    "    \n",
    "    traces_filtered.write.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/9-15-min-filter/MO_1510{day}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8c4781e35f465994eb7860ff929824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>9</td><td>application_1611162050680_0010</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-92-88.ec2.internal:20888/proxy/application_1611162050680_0010/\" >Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-95-152.ec2.internal:8042/node/containerlogs/container_1611162050680_0010_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting haversine\n",
      "  Using cached https://files.pythonhosted.org/packages/f4/52/a13286844780c7b1740edbbee8a8f0524e2a6d51c068b59dda39a6a119f5/haversine-2.3.0-py2.py3-none-any.whl\n",
      "Installing collected packages: haversine\n",
      "Successfully installed haversine-2.3.0"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"haversine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d882c314294b3891500846f72ec9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating Speed for  1 hour\n",
    "from haversine import haversine, Unit\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# calculating speed for each register\n",
    "def calculate_speed(lon1,lat1,lon2,lat2,time_variation):\n",
    "    \n",
    "    # if lon2 and lat2 are available\n",
    "    if lon2 and lat2 and time_variation != 0:\n",
    "        coord_1 = float(lat1),float(lon1)\n",
    "        coord_2 = float(lat2),float(lon2)\n",
    "        distance = haversine(coord_1,coord_2,unit=Unit.METERS)\n",
    "        \n",
    "        # converting the speed from m/s to km/h multiplying by 3.6\n",
    "        return (distance/float(time_variation)) * 3.6\n",
    "    \n",
    "    # it there is no lat and long or time_variation = 0 \n",
    "    \n",
    "    else:\n",
    "        if time_variation == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "get_speed_udf = F.udf(calculate_speed, FloatType())\n",
    "\n",
    "window = Window.partitionBy(\"id_avl\",\"line_id\").orderBy('dt_avl') \n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    \n",
    "    # reading traces\n",
    "    traces = spark.read.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/9-one-hour-filter/MO_1510{day}/\")\n",
    "    \n",
    "    traces = traces.withColumnRenamed(\"trace_x\", \"longitude\").withColumnRenamed(\"trace_y\", \"latitude\")\n",
    "    \n",
    "    # getting time variation\n",
    "    traces_time_variation = traces.select(\"*\", (F.to_timestamp('dt_avl').cast(LongType()) - F.to_timestamp(F.lag(\"dt_avl\").over(window)).cast(LongType())).alias(\"time_variation\"))\n",
    "    \n",
    "    # getting speed based on bus location\n",
    "    traces_speed_bus_location = traces_time_variation.select(\"*\", get_speed_udf(F.col(\"longitude\"),F.col(\"latitude\"),F.lag(F.col(\"longitude\")).over(window),F.lag(F.col(\"latitude\")).over(window),F.col(\"time_variation\")).alias(\"speed\"))\n",
    "    \n",
    "    traces_speed_bus_location.write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/10-one-hour-filter-speed-calculation/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792c5685bbaf486b80ffca1969399122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating Speed for 30 min \n",
    "from haversine import haversine, Unit\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# calculating speed for each register\n",
    "def calculate_speed(lon1,lat1,lon2,lat2,time_variation):\n",
    "    \n",
    "    # if lon2 and lat2 are available\n",
    "    if lon2 and lat2 and time_variation != 0:\n",
    "        coord_1 = float(lat1),float(lon1)\n",
    "        coord_2 = float(lat2),float(lon2)\n",
    "        distance = haversine(coord_1,coord_2,unit=Unit.METERS)\n",
    "        \n",
    "        # converting the speed from m/s to km/h multiplying by 3.6\n",
    "        return (distance/float(time_variation)) * 3.6\n",
    "    \n",
    "    # it there is no lat and long or time_variation = 0 \n",
    "    \n",
    "    else:\n",
    "        if time_variation == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "get_speed_udf = F.udf(calculate_speed, FloatType())\n",
    "\n",
    "window = Window.partitionBy(\"id_avl\",\"line_id\").orderBy('dt_avl') \n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    \n",
    "    # reading traces\n",
    "    traces = spark.read.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/9-30-min-filter/MO_1510{day}/\")\n",
    "    \n",
    "    traces = traces.withColumnRenamed(\"trace_x\", \"longitude\").withColumnRenamed(\"trace_y\", \"latitude\")\n",
    "    \n",
    "    # getting time variation\n",
    "    traces_time_variation = traces.select(\"*\", (F.to_timestamp('dt_avl').cast(LongType()) - F.to_timestamp(F.lag(\"dt_avl\").over(window)).cast(LongType())).alias(\"time_variation\"))\n",
    "    \n",
    "    # getting speed based on bus location\n",
    "    traces_speed_bus_location = traces_time_variation.select(\"*\", get_speed_udf(F.col(\"longitude\"),F.col(\"latitude\"),F.lag(F.col(\"longitude\")).over(window),F.lag(F.col(\"latitude\")).over(window),F.col(\"time_variation\")).alias(\"speed\"))\n",
    "    \n",
    "    traces_speed_bus_location.write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/10-30-min-filter-speed-calculation/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8e3a9d11234cba85c77692bbcdb76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Speed Filter for 1 hour filter\n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    \n",
    "    traces = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/10-one-hour-filter-speed-calculation/MO_1510\"+str(day)+\"/\")    \n",
    "    traces_new = traces.filter(\"speed > 0.1\").filter(\"speed < 80\")\n",
    "    traces_new.write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/11-speed-calculation-filtered-one-hour-filter/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcff3fb416f45e199d8b48546a7500a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Speed Filter for 30 min filter\n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    traces = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/10-30-min-filter-speed-calculation/MO_1510\"+str(day)+\"/\")    \n",
    "    traces_new = traces.filter(\"speed > 0.1\").filter(\"speed < 80\")\n",
    "    traces_new.write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/11-speed-calculation-filtered-30-min-filter/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Degree Metrics Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76c5ebb781f40d895d334bfe6ea0bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating graph - One Hour\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    traces = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/11-speed-calculation-filtered-one-hour-filter/MO_1510\"+str(day)+\"/\")\n",
    "    df = traces.repartition(150)\n",
    "    \n",
    "    df_graph_id = df\\\n",
    "        .withColumn('minute_avl',F.minute(F.col(\"dt_avl\")))\\\n",
    "        .withColumn('graph_id',F.concat(F.col(\"hour_avl\"),F.lit(\"-\"),F.col(\"minute_avl\"),F.lit(\"-\"),F.col(\"region\")))\\\n",
    "        .drop(\"hour_diff\",\"dt_avl\",\"speed\")\n",
    "\n",
    "    df_graph_id.repartition(\"graph_id\").write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/12-traces-graph-id-one-hour-filter/MO_1510\"+str(day)+\"/\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbae2f4ac62f4d1fa2fe8435a09abbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating graph - 30 min\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    traces = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/11-speed-calculation-filtered-30-min-filter/MO_1510\"+str(day)+\"/\")\n",
    "    df = traces.repartition(150)\n",
    "    \n",
    "    df_graph_id = df\\\n",
    "        .withColumn('minute_avl',F.minute(F.col(\"dt_avl\")))\\\n",
    "        .withColumn('graph_id',F.concat(F.col(\"hour_avl\"),F.lit(\"-\"),F.col(\"minute_avl\"),F.lit(\"-\"),F.col(\"region\")))\\\n",
    "        .drop(\"hour_diff\",\"dt_avl\",\"speed\")\n",
    "\n",
    "    df_graph_id.repartition(\"graph_id\").write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/12-traces-graph-id-30-min-filter/MO_1510\"+str(day)+\"/\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2529a4172424f0e8884f6578667a311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# joining the dataset - 1 hour filter\n",
    "\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    df = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/12-traces-graph-id-one-hour-filter/MO_1510\"+str(day)+\"/\")\n",
    "\n",
    "    df2 = df\n",
    "\n",
    "    df.alias('df1').join(df2.alias(\"df2\"),on=[\"graph_id\"],how=\"outer\")\\\n",
    "        .select(\n",
    "            f.col(\"df1.id_avl\").alias(\"id_avl_1\"),\n",
    "            f.col(\"df1.line_id\").alias(\"line_1\"),\n",
    "            f.col(\"df1.latitude\").alias(\"latitude_1\"),\n",
    "            f.col(\"df1.longitude\").alias(\"longitude_1\"),\n",
    "            f.col(\"df2.id_avl\").alias(\"id_avl_2\"),\n",
    "            f.col(\"df2.line_id\").alias(\"line_2\"),\n",
    "            f.col(\"df2.latitude\").alias(\"latitude_2\"),\n",
    "            f.col(\"df2.longitude\").alias(\"longitude_2\"),\n",
    "            f.col(\"df1.hour_avl\").alias(\"hour_avl\"),\n",
    "            f.col(\"df1.minute_avl\").alias(\"minute_avl\"),\n",
    "            f.col(\"df1.region\").alias(\"region\"),\n",
    "            f.col(\"graph_id\").alias(\"graph_id\"),\n",
    "\n",
    "    ).write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/13-joined-graph-one-hour/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b5c476b72c43149489f494ff3e5dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# joining the dataset - 30 min\n",
    "\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    df = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/12-traces-graph-id-30-min-filter/MO_1510\"+str(day)+\"/\")\n",
    "\n",
    "    df2 = df\n",
    "\n",
    "    df.alias('df1').join(df2.alias(\"df2\"),on=[\"graph_id\"],how=\"outer\")\\\n",
    "        .select(\n",
    "            f.col(\"df1.id_avl\").alias(\"id_avl_1\"),\n",
    "            f.col(\"df1.line_id\").alias(\"line_1\"),\n",
    "            f.col(\"df1.latitude\").alias(\"latitude_1\"),\n",
    "            f.col(\"df1.longitude\").alias(\"longitude_1\"),\n",
    "            f.col(\"df2.id_avl\").alias(\"id_avl_2\"),\n",
    "            f.col(\"df2.line_id\").alias(\"line_2\"),\n",
    "            f.col(\"df2.latitude\").alias(\"latitude_2\"),\n",
    "            f.col(\"df2.longitude\").alias(\"longitude_2\"),\n",
    "            f.col(\"df1.hour_avl\").alias(\"hour_avl\"),\n",
    "            f.col(\"df1.minute_avl\").alias(\"minute_avl\"),\n",
    "            f.col(\"df1.region\").alias(\"region\"),\n",
    "            f.col(\"graph_id\").alias(\"graph_id\"),\n",
    "\n",
    "    ).write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/13-joined-graph-30-min/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112487b8f10547d8909c4efe86b29bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# eliminating duplicates - 1 Hour\n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    joined = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/13-joined-graph-one-hour/MO_1510\"+str(day)+\"/\")\n",
    "    joined.repartition(\"graph_id\").filter(\"id_avl_1 != id_avl_2\").write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/14-no-duplicated-one-hour/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8182a9feb598473794dbafc75d95ce27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# eliminating duplicates - 30min\n",
    "\n",
    "days_to_analyze = [1,4,5,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    joined = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/13-joined-graph-30-min/MO_1510\"+str(day)+\"/\")\n",
    "    joined.repartition(\"graph_id\").filter(\"id_avl_1 != id_avl_2\").write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/14-no-duplicated-30-min/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b21b8eb7afd454d9252526d9507dbaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b0375da3814b619070df6d0a7c04ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b21b8eb7afd454d9252526d9507dbaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting haversine\n",
      "  Using cached https://files.pythonhosted.org/packages/f4/52/a13286844780c7b1740edbbee8a8f0524e2a6d51c068b59dda39a6a119f5/haversine-2.3.0-py2.py3-none-any.whl\n",
      "Installing collected packages: haversine\n",
      "Successfully installed haversine-2.3.0Collecting haversine\n",
      "  Using cached https://files.pythonhosted.org/packages/f4/52/a13286844780c7b1740edbbee8a8f0524e2a6d51c068b59dda39a6a119f5/haversine-2.3.0-py2.py3-none-any.whl\n",
      "Installing collected packages: haversine\n",
      "Successfully installed haversine-2.3.0"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"haversine\")\n",
    "\n",
    "from haversine import haversine, Unit\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "def get_distance(lat1,lon1,lat2,lon2):\n",
    "    coord_1 = (lat1,lon1)\n",
    "    coord_2 = (lat2,lon2)\n",
    "\n",
    "    distance = haversine(coord_1,coord_2,unit=Unit.METERS)\n",
    "    \n",
    "    return distance\n",
    "    \n",
    "get_distance_udf = F.udf(get_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa984021c4b429ab6b756d9db75ce8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de30706040c40818b29f1de62d92288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa984021c4b429ab6b756d9db75ce8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating distances - 1 hour\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    no_repeated = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/14-no-duplicated-one-hour/MO_1510\"+str(day)+\"/\")\n",
    "    distance = no_repeated.withColumn(\"distance\",\n",
    "                    get_distance_udf(F.col(\"latitude_1\"),F.col(\"longitude_1\"),F.col(\"latitude_2\"),F.col(\"longitude_2\")))\n",
    "\n",
    "    df_final = distance.repartition(\"graph_id\")\n",
    "\n",
    "    df_final.filter(\"distance <= 100\")\\\n",
    "        .repartition(\"graph_id\")\\\n",
    "        .write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/15-distances-100m-one-hour/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4953d5a1828b488185ddcc81462001b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4953d5a1828b488185ddcc81462001b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ce2092bdf6466ba2bd394e85a8135b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating distances - 30 min\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    no_repeated = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/14-no-duplicated-30-min/MO_1510\"+str(day)+\"/\")\n",
    "    distance = no_repeated.withColumn(\"distance\",\n",
    "                    get_distance_udf(F.col(\"latitude_1\"),F.col(\"longitude_1\"),F.col(\"latitude_2\"),F.col(\"longitude_2\")))\n",
    "\n",
    "    df_final = distance.repartition(\"graph_id\")\n",
    "\n",
    "    df_final.filter(\"distance <= 100\")\\\n",
    "        .repartition(\"graph_id\")\\\n",
    "        .write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/15-distances-100m-30-min/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68c99db5ff24a19a2f1c370b9eb8767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68c99db5ff24a19a2f1c370b9eb8767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a147c85081e4fa49df637cba79800cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dropping duplicates in each graph - 1 hour\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    distances = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/15-distances-100m-one-hour/MO_1510\"+str(day)+\"/\")\n",
    "    df = distances.drop_duplicates(subset=[\"graph_id\",\"id_avl_1\",\"id_avl_2\"])\n",
    "    df.repartition(\"graph_id\").write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/16-no-repeated-contact-on-graph-one-hour/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae50737c15f4bb7bcc0f9169a65160f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae50737c15f4bb7bcc0f9169a65160f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82f7128b8334f7293861dddfd1519db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dropping duplicates in each graph - 1 hour\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    distances = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/15-distances-100m-30-min/MO_1510\"+str(day)+\"/\")\n",
    "    df = distances.drop_duplicates(subset=[\"graph_id\",\"id_avl_1\",\"id_avl_2\"])\n",
    "    df.repartition(\"graph_id\").write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/16-no-repeated-contact-on-graph-30-min/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dce26c7640246568ce1d2f3107e7831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dce26c7640246568ce1d2f3107e7831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcdf490571f482484960b16b8fda9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Node Degree per vehicle per graph - 1 hour\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "for day in days_to_analyze:\n",
    "    \n",
    "    df = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/16-no-repeated-contact-on-graph-one-hour/MO_1510\"+str(day)+\"/\")\n",
    "    df_counts = df.groupby(\"id_avl_1\",\"graph_id\").agg(F.countDistinct(\"id_avl_2\").alias(\"number_connections\"))\n",
    "\n",
    "    df_counts.write.parquet(\"s3://mobility-traces-sp/metrics-calculation/using-new-map-matching-filter/connectivity-metrics/connections-per-vehicle-per-graph-one-hour/MO_1510\"+str(day)+\"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2872d9d4b21e471bb9eaf596748a8421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2872d9d4b21e471bb9eaf596748a8421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d164820837b458f974e7d9ecbfea78a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Node Degree per vehicle per graph - 30min\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "for day in days_to_analyze:\n",
    "    \n",
    "    df = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-new-map-matching-filter/16-no-repeated-contact-on-graph-30-min/MO_1510\"+str(day)+\"/\")\n",
    "    df_counts = df.groupby(\"id_avl_1\",\"graph_id\").agg(F.countDistinct(\"id_avl_2\").alias(\"number_connections\"))\n",
    "\n",
    "    df_counts.write.parquet(\"s3://mobility-traces-sp/metrics-calculation/using-new-map-matching-filter/connectivity-metrics/connections-per-vehicle-per-graph-30-min/MO_1510\"+str(day)+\"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe82c4923394cb8b67e44eee04f34e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe82c4923394cb8b67e44eee04f34e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe82c4923394cb8b67e44eee04f34e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f72669960c4c9fa18f8d68e84488a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f72669960c4c9fa18f8d68e84488a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Node Degree avg per minute - 1 Hour\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "for day in days_to_analyze:\n",
    "    df = spark.read.parquet(\"s3://mobility-traces-sp/metrics-calculation/using-new-map-matching-filter/connectivity-metrics/connections-per-vehicle-per-graph-one-hour/MO_1510\"+str(day)+\"/\") \n",
    "\n",
    "    df = df.withColumn('splitted', F.split(df['graph_id'], '-'))\\\n",
    "        .withColumn('hour', F.col('splitted')[0])\\\n",
    "        .withColumn('minute', F.col('splitted')[1])\\\n",
    "        .withColumn('hour-minute', F.concat(F.col('hour'),F.lit(\":\"),F.col(\"minute\")))\\\n",
    "        .withColumn('region', F.col('splitted')[2])\\\n",
    "        .drop(\"splitted\")\n",
    "    \n",
    "    df = df.groupby(\"hour-minute\").agg(f.avg(\"number_connections\").alias(\"avg_degree\"))\\\n",
    "            .withColumn('time', F.date_format('hour-minute','HH:mm'))\\\n",
    "            .drop(\"hour-minute\")\n",
    "    \n",
    "    df.write.parquet(\"s3://mobility-traces-sp/metrics-calculation/using-new-map-matching-filter/connectivity-metrics/connections-degree-per-minute-one-hour/MO_1510\"+str(day)+\"/\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d79e26d591545e8b2ab941823f9559d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d79e26d591545e8b2ab941823f9559d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d79e26d591545e8b2ab941823f9559d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb0dfee460d4ffb8df06e07786ded54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb0dfee460d4ffb8df06e07786ded54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Node Degree avg per minute - 30min\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "for day in days_to_analyze:\n",
    "    df = spark.read.parquet(\"s3://mobility-traces-sp/metrics-calculation/using-new-map-matching-filter/connectivity-metrics/connections-per-vehicle-per-graph-30-min/MO_1510\"+str(day)+\"/\") \n",
    "\n",
    "    df = df.withColumn('splitted', F.split(df['graph_id'], '-'))\\\n",
    "        .withColumn('hour', F.col('splitted')[0])\\\n",
    "        .withColumn('minute', F.col('splitted')[1])\\\n",
    "        .withColumn('hour-minute', F.concat(F.col('hour'),F.lit(\":\"),F.col(\"minute\")))\\\n",
    "        .withColumn('region', F.col('splitted')[2])\\\n",
    "        .drop(\"splitted\")\n",
    "    \n",
    "    df = df.groupby(\"hour-minute\").agg(f.avg(\"number_connections\").alias(\"avg_degree\"))\\\n",
    "            .withColumn('time', F.date_format('hour-minute','HH:mm'))\\\n",
    "            .drop(\"hour-minute\")\n",
    "    \n",
    "    df.write.parquet(\"s3://mobility-traces-sp/metrics-calculation/using-new-map-matching-filter/connectivity-metrics/connections-degree-per-minute-30-min/MO_1510\"+str(day)+\"/\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
