{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating metrics using speed filter --> eliminates registers speed < 2km and speed > 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4ca3f0270e4253848e684e6c75e835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1611024810140_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-90-231.ec2.internal:20888/proxy/application_1611024810140_0001/\" >Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-80-249.ec2.internal:8042/node/containerlogs/container_1611024810140_0001_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filtering registers speed < 2km and speed > 80\n",
    "for day in range(1,32):\n",
    "    traces = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/10-speed-calculation-based-bus-location/MO_1510\"+str(day)+\"/\")    \n",
    "    traces_new = traces.filter(\"speed >= 2\").filter(\"speed < 80\")\n",
    "    traces_new.write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/20-speed-calculation-filtered/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Active Buses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84af31c39f8540be920fb9a59c026375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading https://files.pythonhosted.org/packages/13/4c/e81c2f215e93a6cb5efdaa991669e3ef1ec6ecfe4407c582c3dfc7d2c281/boto3-1.16.56-py2.py3-none-any.whl (130kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0 (from boto3)\n",
      "  Downloading https://files.pythonhosted.org/packages/ea/43/4b4a1b26eb03a429a4c37ca7fdf369d938bd60018fc194e94b8379b0c77c/s3transfer-0.3.4-py2.py3-none-any.whl (69kB)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3)\n",
      "Collecting botocore<1.20.0,>=1.19.56 (from boto3)\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/72/c904c62945127699aac8aa5bbd508ec851d55da46aaf1072c061de3eb6fa/botocore-1.19.56-py2.py3-none-any.whl (7.2MB)\n",
      "Collecting python-dateutil<3.0.0,>=2.1 (from botocore<1.20.0,>=1.19.56->boto3)\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "Collecting urllib3<1.27,>=1.25.4; python_version != \"3.4\" (from botocore<1.20.0,>=1.19.56->boto3)\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/71/45d36a8df68f3ebb098d6861b2c017f3d094538c0fb98fa61d4dc43e69b9/urllib3-1.26.2-py2.py3-none-any.whl (136kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.56->boto3)\n",
      "Installing collected packages: python-dateutil, urllib3, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.16.56 botocore-1.19.56 python-dateutil-2.8.1 s3transfer-0.3.4 urllib3-1.26.2"
     ]
    }
   ],
   "source": [
    "# installing required packages for this notebook session\n",
    "sc.install_pypi_package(\"boto3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32261329eb04d199e1031960a767e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'D41CC9E21B30B075', 'HostId': 'eH5jk0FAXdW3ZAplwiuU6WfjragHeh6gFSfe6WrXpf/PCxWElzzKaqHsWTZVecVUWqmhmZJ49UA=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'eH5jk0FAXdW3ZAplwiuU6WfjragHeh6gFSfe6WrXpf/PCxWElzzKaqHsWTZVecVUWqmhmZJ49UA=', 'x-amz-request-id': 'D41CC9E21B30B075', 'date': 'Tue, 19 Jan 2021 03:35:05 GMT', 'etag': '\"fa62f25d0d50a8fef589cbb4a5fc87b6\"', 'content-length': '0', 'server': 'AmazonS3'}, 'RetryAttempts': 0}, 'ETag': '\"fa62f25d0d50a8fef589cbb4a5fc87b6\"'}"
     ]
    }
   ],
   "source": [
    "# Total vehicles per day\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import boto3\n",
    "\n",
    "csv_out = \"day,number_of_vehicles\\n\"\n",
    "\n",
    "for day in range(1,32):\n",
    "    traces = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/20-speed-calculation-filtered/MO_1510\"+str(day)+\"/\")\n",
    "    n_vehicles_day = traces.select(F.countDistinct(\"id_avl\").alias(\"count\")).collect()[0][\"count\"]\n",
    "    \n",
    "    csv_out += f\"MO_1510{day},{n_vehicles_day}\\n\"\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# writing results in S3\n",
    "s3.put_object(Body=bytes(csv_out,\"utf-8\"), Bucket='mobility-traces-sp', Key='metrics-calculation/using-speed-2-80/actives-buses/active-buses-per-day.csv')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683e5d46ed1846a18e4c8de87eadc4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Number of vehicles per hour per day\n",
    "for day in range(1,32):\n",
    "    traces = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/20-speed-calculation-filtered/MO_1510\"+str(day)+\"/\")\n",
    "    df = traces.groupby(\"hour_avl\").agg(F.countDistinct(\"id_avl\").alias(\"number_buses\"))\n",
    "    df.write.parquet(f\"s3://mobility-traces-sp/metrics-calculation/using-speed-2-80/actives-buses/active-buses-per-hour/MO_1510{day}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ca8086b5d741308434b0603f2cced9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Number of vehicles per hour and region per day\n",
    "for day in range(1,32):\n",
    "    traces = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/20-speed-calculation-filtered/MO_1510\"+str(day)+\"/\")\n",
    "    df = traces.groupby(\"hour_avl\",\"region\").agg(F.countDistinct(\"id_avl\").alias(\"number_buses\"))\n",
    "    df.write.parquet(f\"s3://mobility-traces-sp/metrics-calculation/using-speed-2-80/actives-buses/active-buses-per-hour-per-region/MO_1510{day}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda9255f20ca488a9ffdf104dd8ee4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# calculating speed per vehicle\n",
    "for day in range(1,32):\n",
    "    traces = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/20-speed-calculation-filtered/MO_1510\"+str(day)+\"/\")\n",
    "    df_speed = traces.groupby(\"id_avl\",\"line_id\").agg(F.avg(\"speed\").alias(\"avg_speed\"),F.stddev(\"speed\").alias(\"speed_stddev\"))\n",
    "    df_speed.write.parquet(\"s3://mobility-traces-sp/metrics-calculation/using-speed-2-80/speed-calculation/speed-per-vehicle/MO_1510\"+str(day)+\"/\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce54fe7ed4240a9af371ee795674506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Package already installed for current Spark context!\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/context.py\", line 1110, in install_pypi_package\n",
      "    raise ValueError(\"Package already installed for current Spark context!\")\n",
      "ValueError: Package already installed for current Spark context!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# installing required packages for this notebook session\n",
    "sc.install_pypi_package(\"boto3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c811049aa50c4310b640eeb0184f47af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'B02806C6248827C6', 'HostId': 'qmAyY4UyGfZEX05e9mMiB4kzCSlePbHIuo5POdgeqGtP5r55GMGRZCIJ3B9Yp5reuspwJR+1iCQ=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'qmAyY4UyGfZEX05e9mMiB4kzCSlePbHIuo5POdgeqGtP5r55GMGRZCIJ3B9Yp5reuspwJR+1iCQ=', 'x-amz-request-id': 'B02806C6248827C6', 'date': 'Tue, 19 Jan 2021 03:54:09 GMT', 'etag': '\"c2c202a14c24c3e359580ec191ad7658\"', 'content-length': '0', 'server': 'AmazonS3'}, 'RetryAttempts': 0}, 'ETag': '\"c2c202a14c24c3e359580ec191ad7658\"'}"
     ]
    }
   ],
   "source": [
    "# avg speed per day\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# statistics speed per vehicle\n",
    "csv_out_vehicle = \"day,n_vehicles,n_lines,n_vehicles_lines,avg_speed,avg_speed_min,avg_speed_max,avg_speed_stddev,avg_speed_quantile_6.25,avg_speed_quantile_12.5,avg_speed_quantile_25,avg_speed_quantile_50,avg_speed_quantile_75\\n\"\n",
    "\n",
    "for day in range(1,32):\n",
    "    # speed by vehicle per line\n",
    "    speeds_per_vehicle = spark.read.parquet(\"s3://mobility-traces-sp/metrics-calculation/using-speed-2-80/speed-calculation/speed-per-vehicle/MO_1510\"+str(day)+\"/\")\n",
    "    \n",
    "    sizes = speeds_per_vehicle.select(F.countDistinct(\"id_avl\").alias(\"vehicles\"),\n",
    "                                      F.countDistinct(\"line_id\").alias(\"lines\"),\n",
    "                                      F.countDistinct(\"id_avl\",\"line_id\").alias(\"vehicles_lines\")\n",
    "                                    ).collect()\n",
    "    \n",
    "    stats = speeds_per_vehicle.agg(F.mean('avg_speed').alias('mean'),\n",
    "                       F.min('avg_speed').alias('min'),\n",
    "                       F.max('avg_speed').alias('max'),\n",
    "                       F.stddev('avg_speed').alias(\"stddev\")).collect()\n",
    "    \n",
    "    quantiles = speeds_per_vehicle.approxQuantile(\"avg_speed\", [0.0625,0.125,0.25,0.5,0.75], 0.0001)\n",
    "    \n",
    "    csv_out_vehicle += \"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\"\\\n",
    "        .format(\"MO_1510\"+str(day),\n",
    "                sizes[0][\"vehicles\"],sizes[0][\"lines\"],sizes[0][\"vehicles_lines\"],\n",
    "                stats[0][\"mean\"],stats[0][\"min\"],stats[0][\"max\"],stats[0][\"stddev\"],\n",
    "                quantiles[0],quantiles[1],quantiles[2],quantiles[3],quantiles[4]\n",
    "        )\n",
    "\n",
    "import boto3   \n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "s3.put_object(Body=bytes(csv_out_vehicle,\"utf-8\"), Bucket='mobility-traces-sp', Key='metrics-calculation/using-speed-2-80/speed-calculation/statistics/1-speed_per_vehicle_stats.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2802f753ded4905b0590450d3f05b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating speed by hour per day\n",
    "# 1- Calculating the avg speed per bus per hour --> groupby id_avl,line_id,hour\n",
    "# 2- Calculating the avg speed per hour per day --> groupby hour\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# calculating speed per hour per day\n",
    "for day in range(1,32):\n",
    "    # Reading traces\n",
    "    traces = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/20-speed-calculation-filtered/MO_1510\"+str(day)+\"/\")\n",
    "    \n",
    "    # Calculating speed by vehicle per hour\n",
    "    df_speed_hour_per_vehicle = traces.groupby(\"id_avl\",\"line_id\",\"hour_avl\").agg(F.avg(\"speed\").alias(\"avg_speed\"),F.stddev(\"speed\").alias(\"speed_stddev\"))\n",
    "    df_speed_hour_per_vehicle.write.parquet(\"s3://mobility-traces-sp/metrics-calculation/using-speed-2-80/speed-calculation/speed-per-vehicle-per-hour/MO_1510\"+str(day)+\"/\")\n",
    "    \n",
    "    # Calculating speed by hour per day\n",
    "    df_speed_hour_day = df_speed_hour_per_vehicle.groupby(\"hour_avl\").agg(F.avg(\"avg_speed\").alias(\"avg_speed\"),F.stddev(\"avg_speed\").alias(\"speed_stddev\"))\n",
    "    df_speed_hour_day.write.parquet(\"s3://mobility-traces-sp/metrics-calculation/using-speed-2-80/speed-calculation/speed-per-hour-per-day/MO_1510\"+str(day)+\"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56fb70f04f13499ab26f2f9f88543256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/notebook-env/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/notebook-env/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/notebook-env/lib/python3.7/site-packages/awseditorssparkmonitoringwidget-1.0-py3.7.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n",
      "    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\n",
      "KeyError: 1598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating speed by region per day\n",
    "# 1- Calculating the avg speed per bus per region --> groupby id_avl,line_id,region\n",
    "# 2- Calculating the avg speed per region per day --> groupby region\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# calculating speed per region per day\n",
    "for day in range(1,32):\n",
    "    # Reading traces\n",
    "    traces = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/20-speed-calculation-filtered/MO_1510\"+str(day)+\"/\")\n",
    "    \n",
    "    # Calculating speed by vehicle per region\n",
    "    df_speed_region_per_vehicle = traces.groupby(\"id_avl\",\"line_id\",\"region\").agg(F.avg(\"speed\").alias(\"avg_speed\"),F.stddev(\"speed\").alias(\"speed_stddev\"))\n",
    "    df_speed_region_per_vehicle.write.parquet(\"s3://mobility-traces-sp/metrics-calculation/using-speed-2-80/speed-calculation/speed-per-vehicle-per-region/MO_1510\"+str(day)+\"/\")\n",
    "    \n",
    "    # Calculating speed by region per day\n",
    "    df_speed_region_day = df_speed_region_per_vehicle.groupby(\"region\").agg(F.avg(\"avg_speed\").alias(\"avg_speed\"),F.stddev(\"avg_speed\").alias(\"speed_stddev\"))\n",
    "    df_speed_region_day.write.parquet(\"s3://mobility-traces-sp/metrics-calculation/using-speed-2-80/speed-calculation/speed-per-region-per-day/MO_1510\"+str(day)+\"/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectivity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying graph_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab63c5d87dbf4d199365a5de64b89833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "for day in range(1,32):\n",
    "    traces = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/20-speed-calculation-filtered/MO_1510\"+str(day)+\"/\")\n",
    "    df = traces.repartition(150)\n",
    "    \n",
    "    df_graph_id = df\\\n",
    "        .withColumn('minute_avl',F.minute(F.col(\"dt_avl\")))\\\n",
    "        .withColumn('graph_id',F.concat(F.col(\"hour_avl\"),F.lit(\"-\"),F.col(\"minute_avl\"),F.lit(\"-\"),F.col(\"region\")))\\\n",
    "        .drop(\"hour_diff\",\"dt_avl\",\"speed\")\n",
    "\n",
    "    df_graph_id.repartition(\"graph_id\").write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/21-traces-graph-1-minute-with-graph-id/MO_1510\"+str(day)+\"/\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4058aa5ba6b14daf8392e478ad36af42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# joining the dataset\n",
    "\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "days = [23,24,25,26,27,28,29,30,31]\n",
    "\n",
    "for day in days:\n",
    "    df = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/21-traces-graph-1-minute-with-graph-id/MO_1510\"+str(day)+\"/\")\n",
    "\n",
    "    df2 = df\n",
    "\n",
    "    df.alias('df1').join(df2.alias(\"df2\"),on=[\"graph_id\"],how=\"outer\")\\\n",
    "        .select(\n",
    "            f.col(\"df1.id_avl\").alias(\"id_avl_1\"),\n",
    "            f.col(\"df1.line_id\").alias(\"line_1\"),\n",
    "            f.col(\"df1.latitude\").alias(\"latitude_1\"),\n",
    "            f.col(\"df1.longitude\").alias(\"longitude_1\"),\n",
    "            f.col(\"df2.id_avl\").alias(\"id_avl_2\"),\n",
    "            f.col(\"df2.line_id\").alias(\"line_2\"),\n",
    "            f.col(\"df2.latitude\").alias(\"latitude_2\"),\n",
    "            f.col(\"df2.longitude\").alias(\"longitude_2\"),\n",
    "            f.col(\"df1.hour_avl\").alias(\"hour_avl\"),\n",
    "            f.col(\"df1.minute_avl\").alias(\"minute_avl\"),\n",
    "            f.col(\"df1.region\").alias(\"region\"),\n",
    "            f.col(\"graph_id\").alias(\"graph_id\"),\n",
    "\n",
    "    ).write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/22-joined-graph-1-minute/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe72509981e4afea3cb1fcbcf80ead5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting haversine\n",
      "  Using cached https://files.pythonhosted.org/packages/f4/52/a13286844780c7b1740edbbee8a8f0524e2a6d51c068b59dda39a6a119f5/haversine-2.3.0-py2.py3-none-any.whl\n",
      "Installing collected packages: haversine\n",
      "Successfully installed haversine-2.3.0"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"haversine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53b08595a7c46798c4b1df21e0e133f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from haversine import haversine, Unit\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "def get_distance(lat1,lon1,lat2,lon2):\n",
    "    coord_1 = (lat1,lon1)\n",
    "    coord_2 = (lat2,lon2)\n",
    "\n",
    "    distance = haversine(coord_1,coord_2,unit=Unit.METERS)\n",
    "    \n",
    "    return distance\n",
    "    \n",
    "get_distance_udf = F.udf(get_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532908a296fc4f27bd65b7d2db9a0bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# eliminating duplicates\n",
    "for day in range(1,32):\n",
    "    joined = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/22-joined-graph-1-minute/MO_1510\"+str(day)+\"/\")\n",
    "    joined.repartition(\"graph_id\").filter(\"id_avl_1 != id_avl_2\").write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/23-no-duplicated/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "for day in days_to_analyze:\n",
    "    no_repeated = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/23-no-duplicated/MO_1510\"+str(day)+\"/\")\n",
    "    distance = no_repeated.withColumn(\"distance\",\n",
    "                    get_distance_udf(F.col(\"latitude_1\"),F.col(\"longitude_1\"),F.col(\"latitude_2\"),F.col(\"longitude_2\")))\n",
    "\n",
    "    df_final = distance.repartition(\"graph_id\")\n",
    "\n",
    "    df_final.filter(\"distance <= 100\")\\\n",
    "        .repartition(\"graph_id\")\\\n",
    "        .write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/24-no-duplicated-with-all-distances/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554604004daf4406a886f04b3d8c4e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "for day in days_to_analyze:\n",
    "    distances = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/24-no-duplicated-with-all-distances/MO_1510\"+str(day)+\"/\")\n",
    "    df = distances.drop_duplicates(subset=[\"graph_id\",\"id_avl_1\",\"id_avl_2\"])\n",
    "    df.repartition(\"graph_id\").write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/25-no-repeated-contact-only-100-distances/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c78b02340c4e0a93b90fdcd697d263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Node Degree per vehicle per graph\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "for day in days_to_analyze:\n",
    "    \n",
    "    df = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/25-no-repeated-contact-only-100-distances/MO_1510\"+str(day)+\"/\")\n",
    "    df_counts = df.groupby(\"id_avl_1\",\"graph_id\").agg(F.countDistinct(\"id_avl_2\").alias(\"number_connections\"))\n",
    "\n",
    "    df_counts.write.parquet(\"s3://mobility-traces-sp/metrics-calculation/using-speed-2-80/connectivity-metrics/connections-per-vehicle-per-graph/MO_1510\"+str(day)+\"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef1eec38eb24dc3bd6c70b00d4f887e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Node Degree avg per minute\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "for day in days_to_analyze:\n",
    "    df = spark.read.parquet(\"s3://mobility-traces-sp/metrics-calculation/using-speed-2-80/connectivity-metrics/connections-per-vehicle-per-graph/MO_1510\"+str(day)+\"/\") \n",
    "\n",
    "    df = df.withColumn('splitted', F.split(df['graph_id'], '-'))\\\n",
    "        .withColumn('hour', F.col('splitted')[0])\\\n",
    "        .withColumn('minute', F.col('splitted')[1])\\\n",
    "        .withColumn('hour-minute', F.concat(F.col('hour'),F.lit(\":\"),F.col(\"minute\")))\\\n",
    "        .withColumn('region', F.col('splitted')[2])\\\n",
    "        .drop(\"splitted\")\n",
    "    \n",
    "    df = df.groupby(\"hour-minute\").agg(f.avg(\"number_connections\").alias(\"avg_degree\"))\\\n",
    "            .withColumn('time', F.date_format('hour-minute','HH:mm'))\\\n",
    "            .drop(\"hour-minute\")\n",
    "    \n",
    "    df.write.parquet(\"s3://mobility-traces-sp/metrics-calculation/using-speed-2-80/connectivity-metrics/connections-degree-per-minute/MO_1510\"+str(day)+\"/\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373a73a795674ecf86354ee214a27638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 1\n",
      "+-----------------+-----------------+---+---+\n",
      "|              avg|           stddev|max|min|\n",
      "+-----------------+-----------------+---+---+\n",
      "|3.690357977881169|3.396344978033525| 52|  1|\n",
      "+-----------------+-----------------+---+---+\n",
      "\n",
      "[1.0, 3.0, 5.0]\n",
      "Day 5\n",
      "+------------------+------------------+---+---+\n",
      "|               avg|            stddev|max|min|\n",
      "+------------------+------------------+---+---+\n",
      "|3.7534078358463727|3.4847551992377506| 59|  1|\n",
      "+------------------+------------------+---+---+\n",
      "\n",
      "[1.0, 3.0, 5.0]\n",
      "Day 4\n",
      "+------------------+------------------+---+---+\n",
      "|               avg|            stddev|max|min|\n",
      "+------------------+------------------+---+---+\n",
      "|2.3342890031601637|1.8588067594456918| 27|  1|\n",
      "+------------------+------------------+---+---+\n",
      "\n",
      "[1.0, 2.0, 3.0]\n",
      "Day 12\n",
      "+-----------------+------------------+---+---+\n",
      "|              avg|            stddev|max|min|\n",
      "+-----------------+------------------+---+---+\n",
      "|2.396904215117114|1.9351793086571762| 28|  1|\n",
      "+-----------------+------------------+---+---+\n",
      "\n",
      "[1.0, 2.0, 3.0]\n",
      "Day 17\n",
      "+-----------------+------------------+---+---+\n",
      "|              avg|            stddev|max|min|\n",
      "+-----------------+------------------+---+---+\n",
      "|2.894810724442296|2.4461869961674583| 33|  1|\n",
      "+-----------------+------------------+---+---+\n",
      "\n",
      "[1.0, 2.0, 4.0]\n",
      "Day 20\n",
      "+-----------------+-----------------+---+---+\n",
      "|              avg|           stddev|max|min|\n",
      "+-----------------+-----------------+---+---+\n",
      "|3.712361835117105|3.424482793391894| 53|  1|\n",
      "+-----------------+-----------------+---+---+\n",
      "\n",
      "[1.0, 3.0, 5.0]"
     ]
    }
   ],
   "source": [
    "# Degree vehicle per day statistics\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "for day in days_to_analyze:\n",
    "    print(\"Day\",day)\n",
    "    count_connections = spark.read.parquet(f\"s3://mobility-traces-sp/metrics-calculation/using-speed-2-80/connectivity-metrics/connections-per-vehicle-per-graph/MO_1510{day}/\")\n",
    "\n",
    "    count_connections.agg(\n",
    "        F.avg(\"number_connections\").alias(\"avg\"),\n",
    "        F.stddev(\"number_connections\").alias(\"stddev\"),\n",
    "        F.max(\"number_connections\").alias(\"max\"),\n",
    "        F.min(\"number_connections\").alias(\"min\"),\n",
    "    ).show()\n",
    "\n",
    "    quantiles = count_connections.approxQuantile(\"number_connections\", [0.25,0.5,0.75], 0.0001)\n",
    "    print(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679cf72b8f6844e6aa3dc0ae0427d5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Connection_id_column\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Creating a connection_id for each connection with the buses.\n",
    "# Connection_id = id_avl_1+id_avl_2 if id_avl_1 < id_avl_2\n",
    "# Connection_id = id_avl_2+id_avl_1 if id_avl_2 < id_avl_1\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "\n",
    "    df = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/25-no-repeated-contact-only-100-distances/MO_1510\"+str(day)+\"/\")\n",
    "\n",
    "    df = df.withColumn(\"connection_id\",\n",
    "        F.when(F.col(\"id_avl_1\") < F.col(\"id_avl_2\"), F.concat(F.col(\"id_avl_1\"),F.lit(\"-\"),F.col(\"id_avl_2\")))\n",
    "        .otherwise(F.concat(F.col(\"id_avl_2\"),F.lit(\"-\"),F.col(\"id_avl_1\"))))\n",
    "\n",
    "    df = df.repartition(\"graph_id\")\n",
    "\n",
    "\n",
    "\n",
    "    df.write.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/26-no-repeated-contact-only-100-distances-with-connection-id/MO_1510\"+str(day)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823d2afe645a4a229d820023163fe1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saving count of repeated connections\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "\n",
    "    df = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/26-no-repeated-contact-only-100-distances-with-connection-id/MO_1510\"+str(day)+\"/\")\n",
    "\n",
    "    df = df.drop_duplicates(subset=[\"connection_id\",\"graph_id\"])\n",
    "\n",
    "    df_counts = df.groupby(\"connection_id\").agg(F.count(\"connection_id\").alias(\"count_per_day\"))\n",
    "\n",
    "    df_counts.write.parquet(f\"s3://mobility-traces-sp/metrics-calculation/using-speed-2-80/connectivity-metrics/repeated-connection-per-day/MO_1510{day}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f05a676368444c0bca086bb2997093d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 1\n",
      "+-----------------+-----------------+---+---+\n",
      "|              avg|           stddev|max|min|\n",
      "+-----------------+-----------------+---+---+\n",
      "|2.641490255137404|3.357811855685901|166|  1|\n",
      "+-----------------+-----------------+---+---+\n",
      "\n",
      "[1.0, 1.0, 3.0]\n",
      "Day 5\n",
      "+-----------------+-----------------+---+---+\n",
      "|              avg|           stddev|max|min|\n",
      "+-----------------+-----------------+---+---+\n",
      "|2.668634439659038|3.405101187213052|170|  1|\n",
      "+-----------------+-----------------+---+---+\n",
      "\n",
      "[1.0, 2.0, 3.0]\n",
      "Day 4\n",
      "+-----------------+----------------+---+---+\n",
      "|              avg|          stddev|max|min|\n",
      "+-----------------+----------------+---+---+\n",
      "|2.656030673917721|3.17151251960479|151|  1|\n",
      "+-----------------+----------------+---+---+\n",
      "\n",
      "[1.0, 2.0, 3.0]\n",
      "Day 12\n",
      "+-----------------+-----------------+---+---+\n",
      "|              avg|           stddev|max|min|\n",
      "+-----------------+-----------------+---+---+\n",
      "|2.667264523334527|3.215293056650444|100|  1|\n",
      "+-----------------+-----------------+---+---+\n",
      "\n",
      "[1.0, 2.0, 3.0]\n",
      "Day 17\n",
      "+------------------+------------------+---+---+\n",
      "|               avg|            stddev|max|min|\n",
      "+------------------+------------------+---+---+\n",
      "|2.6737308254678664|3.3114493890026084|132|  1|\n",
      "+------------------+------------------+---+---+\n",
      "\n",
      "[1.0, 2.0, 3.0]\n",
      "Day 20\n",
      "+-----------------+-----------------+---+---+\n",
      "|              avg|           stddev|max|min|\n",
      "+-----------------+-----------------+---+---+\n",
      "|2.646652974087235|3.369984932486676|156|  1|\n",
      "+-----------------+-----------------+---+---+\n",
      "\n",
      "[1.0, 1.0, 3.0]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Number of repeated connections per day/duration of the connections\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    print(\"Day\",day)\n",
    "    df = spark.read.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/26-no-repeated-contact-only-100-distances-with-connection-id/MO_1510{day}/\")\n",
    "\n",
    "    df = df.drop_duplicates(subset=[\"connection_id\",\"graph_id\"])\n",
    "\n",
    "    df_counts = df.groupby(\"connection_id\").agg(F.count(\"connection_id\").alias(\"count_per_day\"))\n",
    "\n",
    "    df_counts.agg(\n",
    "        F.avg(\"count_per_day\").alias(\"avg\"),\n",
    "        F.stddev(\"count_per_day\").alias(\"stddev\"),\n",
    "        F.max(\"count_per_day\").alias(\"max\"),\n",
    "        F.min(\"count_per_day\").alias(\"min\"),\n",
    "    ).show()\n",
    "\n",
    "    quantiles = df_counts.approxQuantile(\"count_per_day\", [0.25,0.5,0.75], 0.0001)\n",
    "    print(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f4413718954fbc84706d46b894ee5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 1\n",
      "+--------------------+\n",
      "|number_distinct_conn|\n",
      "+--------------------+\n",
      "|             4007958|\n",
      "+--------------------+\n",
      "\n",
      "+-------------+\n",
      "|total_per_day|\n",
      "+-------------+\n",
      "|     10586982|\n",
      "+-------------+\n",
      "\n",
      "Day 5\n",
      "+--------------------+\n",
      "|number_distinct_conn|\n",
      "+--------------------+\n",
      "|             4047723|\n",
      "+--------------------+\n",
      "\n",
      "+-------------+\n",
      "|total_per_day|\n",
      "+-------------+\n",
      "|     10801893|\n",
      "+-------------+\n",
      "\n",
      "Day 4\n",
      "+--------------------+\n",
      "|number_distinct_conn|\n",
      "+--------------------+\n",
      "|              878401|\n",
      "+--------------------+\n",
      "\n",
      "+-------------+\n",
      "|total_per_day|\n",
      "+-------------+\n",
      "|      2333060|\n",
      "+-------------+\n",
      "\n",
      "Day 12\n",
      "+--------------------+\n",
      "|number_distinct_conn|\n",
      "+--------------------+\n",
      "|              938352|\n",
      "+--------------------+\n",
      "\n",
      "+-------------+\n",
      "|total_per_day|\n",
      "+-------------+\n",
      "|      2502833|\n",
      "+-------------+\n",
      "\n",
      "Day 17\n",
      "+--------------------+\n",
      "|number_distinct_conn|\n",
      "+--------------------+\n",
      "|             1908130|\n",
      "+--------------------+\n",
      "\n",
      "+-------------+\n",
      "|total_per_day|\n",
      "+-------------+\n",
      "|      5101826|\n",
      "+-------------+\n",
      "\n",
      "Day 20\n",
      "+--------------------+\n",
      "|number_distinct_conn|\n",
      "+--------------------+\n",
      "|             4001194|\n",
      "+--------------------+\n",
      "\n",
      "+-------------+\n",
      "|total_per_day|\n",
      "+-------------+\n",
      "|     10589772|\n",
      "+-------------+"
     ]
    }
   ],
   "source": [
    "# Total number of distinct connections per day\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "days_to_analyze = [1,5,4,12,17,20]\n",
    "\n",
    "for day in days_to_analyze:\n",
    "    print(\"Day\",day)\n",
    "    connections = spark.read.parquet(f\"s3://mobility-traces-sp/processed-data-avl-date/using-vehicle-2-80/26-no-repeated-contact-only-100-distances-with-connection-id/MO_1510{day}/\")\n",
    "\n",
    "    connections.agg(F.countDistinct(\"connection_id\").alias(\"number_distinct_conn\")).show()\n",
    "    connections.groupby(\"graph_id\",\"connection_id\").agg(F.countDistinct(\"connection_id\").alias(\"count_novo\"))\\\n",
    "        .agg(F.sum(\"count_novo\").alias(\"total_per_day\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
