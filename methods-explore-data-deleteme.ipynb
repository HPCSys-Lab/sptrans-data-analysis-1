{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring cleaned data\n",
    "# https://runawayhorse001.github.io/LearningApacheSpark/exploration.html\n",
    "#https://towardsdatascience.com/a-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427\n",
    "\n",
    "df.describe(\"coluna\").show()\n",
    "df.describe([“age”]).show()\n",
    "medianAndQuantiles = lifeExpectancyDF.stat.approxQuantile(\"?\",[0.25,0.5,0.75],0.0)\n",
    "df.approxQuantile([\"x\", \"y\", \"z\"], [0.5], 0.25)\n",
    "# selected varables for the demonstration\n",
    "num_cols = ['Account Balance','No of dependents']\n",
    "df.select(num_cols).describe().show()\n",
    "\n",
    "# estatistica de todas as coluna\n",
    "for col in df.columns:\n",
    "    df.describe([col]).show()\n",
    "    \n",
    "    \n",
    ">>> test_df.registerTempTable(\"df\")\n",
    ">>> df2 = sqlContext.sql(\"select agent_id, percentile_approx(payment_amount,0.95) as approxQuantile from df group by agent_id\")\n",
    "\n",
    ">>> df2.show()\n",
    "\n",
    "from pyspark.sql.functions import format_number\n",
    "result = crimes.select([\"Latitude\",\"Longitude\",\"Year\",\"XCoordinate\",\"YCoordinate\"]).describe()\n",
    "result.select(result['summary'],\n",
    "              format_number(result['Latitude'].cast('float'),2).alias('Latitude'),\n",
    "              format_number(result['Longitude'].cast('float'),2).alias('Longitude'),\n",
    "              result['Year'].cast('int').alias('year'),\n",
    "              format_number(result['XCoordinate'].cast('float'),2).alias('XCoordinate'),\n",
    "              format_number(result['YCoordinate'].cast('float'),2).alias('YCoordinate')\n",
    "             ).show()\n",
    "\n",
    "crimes.select(\"PrimaryType\").distinct().show(n = 35)\n",
    "\n",
    "\n",
    "# https://datascienceplus.com/spark-dataframes-exploring-chicago-crimes/\n",
    "max,min,distinct,mean,avg,quantiles,histogram, comparacao entre eles\n",
    "df.agg({\"Lat\":\"avg\"}).show()\n",
    "\n",
    "\n",
    "# https://databricks.com/blog/2015/06/02/statistical-and-mathematical-functions-with-dataframes-in-spark.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic histogram\n",
    "var = 'Age (years)'\n",
    "x = data1[var]\n",
    "bins = np.arange(0, 100, 5.0)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "# the histogram of the data\n",
    "plt.hist(x, bins, alpha=0.8, histtype='bar', color='gold',\n",
    "         ec='black',weights=np.zeros_like(x) + 100. / x.size)\n",
    "\n",
    "plt.xlabel(var)\n",
    "plt.ylabel('percentage')\n",
    "plt.xticks(bins)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(var+\".pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical values aka nome_region\n",
    "\n",
    "# tabela de frequencia\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import rank,sum,col\n",
    "from pyspark.sql import Window\n",
    "\n",
    "window = Window.rowsBetween(Window.unboundedPreceding,Window.unboundedFollowing)\n",
    "# withColumn('Percent %',F.format_string(\"%5.0f%%\\n\",col('Credit_num')*100/col('total'))).\\\n",
    "tab = df.select(['age_class','Credit Amount']).\\\n",
    "   groupBy('age_class').\\\n",
    "   agg(F.count('Credit Amount').alias('Credit_num'),\n",
    "       F.mean('Credit Amount').alias('Credit_avg'),\n",
    "       F.min('Credit Amount').alias('Credit_min'),\n",
    "       F.max('Credit Amount').alias('Credit_max')).\\\n",
    "   withColumn('total',sum(col('Credit_num')).over(window)).\\\n",
    "   withColumn('Percent',col('Credit_num')*100/col('total')).\\\n",
    "   drop(col('total'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
