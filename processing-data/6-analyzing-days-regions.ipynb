{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark_conf = (SparkConf().set(\"spark.speculation\", \"false\"))\n",
    "sc = SparkContext.getOrCreate(conf = spark_conf)\n",
    "\n",
    "# spark = sparkSession\n",
    "hadoop_conf = spark._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "hadoop_conf.set(\"mapreduce.fileoutputcommitter.algorithm.version\",\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting random working days and weekend days for analysis\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "days = set([12]) # 6 days = 3 work days + 2 weekends + 1 holiday\n",
    "weekends = [3,10,17,24,31,4,11,18,25]\n",
    "\n",
    "random_weekend_choice = np.random.choice(weekends, 1)\n",
    "\n",
    "# 1 weekends days\n",
    "days.add(random_weekend_choice[0])\n",
    "\n",
    "work_days = set(list(range(1,32)))\n",
    "\n",
    "valid_days = work_days - set(weekends)\n",
    "\n",
    "random_work_days = np.random.choice(list(valid_days), 2)\n",
    "\n",
    "# 2 work days\n",
    "days.add(random_work_days[0])\n",
    "days.add(random_work_days[1])\n",
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting day's files\n",
    "filenames = [\"MO_1510\" + str(day) for day in days]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing required packages for this notebook session\n",
    "sc.install_pypi_package(\"matplotlib\")\n",
    "sc.install_pypi_package(\"descartes\")\n",
    "sc.install_pypi_package(\"shapely\")\n",
    "sc.install_pypi_package(\"geopandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libs\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "sp_shape = gpd.read_file('s3://mobility-traces-sp/aux-files/shape-sp/DISTRITO_MUNICIPAL_SP_SMDUPolygon.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of all Sao Paulo regions\n",
    "regions = {\n",
    "    \"centro\":[\"ALTO DE PINHEIROS\",\"BARRA FUNDA\",\"BELA VISTA\",\"BELEM\",\"BOM RETIRO\",\"BRAS\",\"CAMBUCI\",\"CONSOLACAO\",\"JARDIM PAULISTA\",\"LAPA\",\"LIBERDADE\",\"MOEMA\",\"MOOCA\",\"PARI\",\"PERDIZES\",\"PINHEIROS\",\"REPUBLICA\",\"SANTA CECILIA\",\"SAUDE\",\"SE\",\"VILA LEOPOLDINA\",\"VILA MARIANA\"],\n",
    "    \"sul\":[\"CAMPO BELO\",\"CAMPO GRANDE\",\"CIDADE ADEMAR\",\"CIDADE DUTRA\",\"GRAJAU\",\"JABAQUARA\",\"MARSILAC\",\"PARELHEIROS\",\"PEDREIRA\",\"SOCORRO\"],\n",
    "    \"noroeste\":[\"SAO DOMINGOS\",\"ANHANGUERA\",\"BRASILANDIA\",\"CACHOEIRINHA\",\"FREGUESIA DO O\",\"JAGUARA\",\"JARAGUA\",\"LIMAO\",\"PERUS\",\"PIRITUBA\"],\n",
    "    \"leste\":[\"ARICANDUVA\",\"ARTUR ALVIM\",\"CARRAO\",\"CIDADE LIDER\",\"CIDADE TIRADENTES\",\"GUAIANASES\",\"IGUATEMI\",\"ITAQUERA\",\"JOSE BONIFACIO\",\"PARQUE DO CARMO\",\"SAO RAFAEL\",\"VILA FORMOSA\",\"VILA MATILDE\",\"SAO MATEUS\"],\n",
    "    \"oeste\":[\"BUTANTA\",\"CAMPO LIMPO\",\"JAGUARE\",\"MORUMBI\",\"RAPOSO TAVARES\",\"RIO PEQUENO\",\"VILA ANDRADE\",\"VILA SONIA\",\"AGUA RASA\"],\n",
    "    \"sudoeste\":[\"SANTO AMARO\",\"CAPAO REDONDO\",\"JARDIM ANGELA\",\"JARDIM SAO LUIS\",\"ITAIM BIBI\"],\n",
    "    \"sudeste\":[\"CURSINO\",\"IPIRANGA\",\"SACOMA\",\"SAO LUCAS\",\"SAPOPEMBA\",\"VILA PRUDENTE\"],\n",
    "    \"nordeste\":[\"TATUAPE\",\"CANGAIBA\",\"ERMELINO MATARAZZO\",\"ITAIM PAULISTA\",\"JARDIM HELENA\",\"LAJEADO\",\"PENHA\",\"PONTE RASA\",\"SAO MIGUEL\",\"VILA CURUCA\",\"VILA JACUI\"],\n",
    "    \"norte\":[\"CASA VERDE\",\"JACANA\",\"MANDAQUI\",\"SANTANA\",\"TREMEMBE\",\"TUCURUVI\",\"VILA GUILHERME\",\"VILA MARIA\",\"VILA MEDEIROS\"],    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking not found regions in the shape\n",
    "regions_shape = list(sp_shape[\"Nome\"])\n",
    "not_found = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding all regions in the shape\n",
    "for key in regions.keys():\n",
    "    for region in regions[key]:\n",
    "        if region not in regions_shape:\n",
    "            not_found.append(region)\n",
    "not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting random Sao Paulo Regions\n",
    "import numpy as np\n",
    "random_regions = set()\n",
    "for key in regions.keys():\n",
    "    list_size = len(regions[key])\n",
    "    choices = np.random.choice(list(range(0, list_size)),2)\n",
    "    random_regions.add(regions[key][choices[0]])\n",
    "    random_regions.add(regions[key][choices[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(random_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting some random regions and day to analyze in the map\n",
    "from pyspark.sql import functions as F\n",
    "def in_region(region):\n",
    "    return region in random_regions\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "in_region_udf = udf(in_region, BooleanType())\n",
    "\n",
    "for file in filenames:\n",
    "    traces = spark.read.parquet(\"s3a://mobility-traces-sp/processed-data/using-server-hour/records-between-6-23-only-sp-server-hour/\"+ file +  \"/\")\n",
    "\n",
    "    new_traces_in_regions = traces.filter(in_region_udf('region'))\n",
    "\n",
    "    for region in random_regions:\n",
    "        traces_region = new_traces_in_regions.filter(col(\"region\") == region)\n",
    "        buses = traces_region.select(\"id_avl\").sample(False, 0.1, seed=0).limit(2).collect()\n",
    "        traces_bus_1 = traces_region.filter(col(\"id_avl\") == buses[0][\"id_avl\"]).sort(col(\"dt_server\"))\n",
    "        traces_bus_2 = traces_region.filter(col(\"id_avl\") == buses[1][\"id_avl\"]).sort(col(\"dt_server\"))\n",
    "        traces_bus_1.repartition(20).write.parquet(\"s3://mobility-traces-sp/processed-data/using-server-hour/exploring-data-on-map-only-sp-6-23-server-hour/\"+file+\"/\"+region+\"/\"+str(buses[0][\"id_avl\"]) + \"/\")\n",
    "        traces_bus_2.repartition(20).write.parquet(\"s3://mobility-traces-sp/processed-data/using-server-hour/exploring-data-on-map-only-sp-6-23-server-hour/\"+file+\"/\"+region+\"/\"+str(buses[1][\"id_avl\"]) + \"/\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
