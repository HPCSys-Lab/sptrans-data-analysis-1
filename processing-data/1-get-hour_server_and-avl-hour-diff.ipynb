{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descrição\n",
    "#\n",
    "# Após verificar se não há valores nulos/vazios nos dados não processados, vamos pré processar os arquivos \n",
    "# para facilitar nos próximos processamentos.\n",
    "#\n",
    "# Este notebook lê os arquivos não processados (raw-data) e adiciona novas colunas \n",
    "# (hour_server, hour_avl, hour_diff).\n",
    "#\n",
    "# Descrição das novas colunas:\n",
    "#\n",
    "# - hour_server: representa a hora inteira de cada registro baseada na data do servidor. \n",
    "# Ex: 2015-10-23 09:07:53.813, então hour_server = 9\n",
    "#\n",
    "# - hour_avl: representa a hora inteira de cada registro baseada na data do equipamento avl\n",
    "# Ex: 2015-10-23 09:07:53.813, então hour_avl = 9\n",
    "#\n",
    "# - hour_diff: representa a diferença entre a data do servidor e a data do avl em segundos\n",
    "# \n",
    "#\n",
    "# Description\n",
    "#\n",
    "# After checking null/empty values in the non processed files, lets pre process the file to ease \n",
    "# next processing tasks.\n",
    "#\n",
    "# This notebook reads files raw-data and adds new columns (hour_server, hour_avl, hour_diff)\n",
    "#\n",
    "# New columns' description:\n",
    "#\n",
    "# - hour_server: the integer number that represents the hour of server date \n",
    "# Ex: 2015-10-23 09:07:53.813, so hour_server = 9\n",
    "#\n",
    "# - hour_avl: the integer number that represents the hour of avl date\n",
    "# Ex: 2015-10-23 09:07:53.813, so hour_avl = 9\n",
    "#\n",
    "# - hour_diff: represents the difference in seconds between server date and avl date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark config\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark_conf = (SparkConf().set(\"spark.speculation\", \"false\"))\n",
    "sc = SparkContext.getOrCreate(conf = spark_conf)\n",
    "\n",
    "# spark = sparkSession\n",
    "hadoop_conf = spark._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "hadoop_conf.set(\"mapreduce.fileoutputcommitter.algorithm.version\",\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "def get_hour_server_and_avl_hour_diff(row):\n",
    "    # split csv lines by comma\n",
    "    fields = row.split(\",\")\n",
    "    \n",
    "    # converts the date strings like 2015-10-23 09:07:53.813, to a date object\n",
    "    date_server = parser.parse(fields[0])\n",
    "    date_avl = parser.parse(fields[1])\n",
    "    \n",
    "    # difference between dates in seconds\n",
    "    date_diff = date_server - date_avl\n",
    "    \n",
    "    # returns the new transformed line with the new columns hour_server, hour_avl, date_diff\n",
    "    return str(fields[0]) + \",\" + str(fields[1])+ \",\" + str(fields[2])+ \",\" + str(fields[3])+ \",\" +str(fields[4])+ \",\" +str(fields[5])+ \",\" +str(fields[6])+ \",\" +str(fields[7])+ \",\" + str(date_server.hour) + \",\" + str(date_avl.hour) + \",\" + str(date_diff.total_seconds()) \n",
    "\n",
    "# october day 1 to day 31\n",
    "for day in range(1,32):\n",
    "    \n",
    "    # reads raw data\n",
    "    traces_hour = sc.textFile(\"s3a://mobility-traces-sp/raw-data/MO_1510\"+ str(day) +  \".csv\").map(get_hour_server_and_avl_hour_diff)\n",
    "    \n",
    "    # save transformed file\n",
    "    traces_hour.repartition(60).saveAsTextFile(\"s3://mobility-traces-sp/raw-hour-dt_server-dt_avl-hour_diff/MO_1510\"+ str(day) + \"/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
