{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the nearest shape for each record in MO file using multiprocessing python lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from haversine import haversine, Unit\n",
    "from math import sin,cos,sqrt,atan2,radians\n",
    "\n",
    "results_global = []\n",
    "\n",
    "machine_cores = 46\n",
    "\n",
    "filename=\"MO_15101\"\n",
    "\n",
    "traces = pd.read_parquet(\"./\"+filename+\"/\")\n",
    "\n",
    "shapes = pd.read_csv(\"shapes.csv\")\n",
    "\n",
    "outsize = len(traces)\n",
    "\n",
    "columns = [\"dt_avl\",\"id_avl\",\"line_id\",\"trace_y\",\"trace_x\",\"hour_avl\",\"hour_diff\",\"region\",\"time_variation\",\"trip_id\",\"direction\",\"route_id\",\"trip_head\",\"shape_id\",\"min_distance\",\"min_shape_sequence\",\"min_shape_coord_lat\",\"min_shape_coord_lon\"]\n",
    "\n",
    "def get_shape(amount, index_start):\n",
    "    results = set()\n",
    "\n",
    "    global traces\n",
    "    global shapes\n",
    "\n",
    "    for i in range(amount):\n",
    "        index_id = index_start + i\n",
    "\n",
    "        line_id = traces[\"line_id\"][index_id]\n",
    "\n",
    "        dt_avl = traces[\"dt_avl\"][index_id]\n",
    "\n",
    "        id_avl = traces[\"id_avl\"][index_id]\n",
    "\n",
    "        hour_avl = traces[\"hour_avl\"][index_id]\n",
    "\n",
    "        hour_diff = traces[\"hour_diff\"][index_id]\n",
    "\n",
    "        region = traces[\"region\"][index_id]\n",
    "\n",
    "        time_variation = traces[\"time_variation\"][index_id]\n",
    "\n",
    "        trip_id = traces[\"trip_id\"][index_id]\n",
    "\n",
    "        direction = traces[\"direction\"][index_id]\n",
    "\n",
    "        route_id = traces[\"route_id\"][index_id]\n",
    "\n",
    "        trip_head = traces[\"trip_headsign\"][index_id]\n",
    "\n",
    "        trace_x = traces[\"longitude\"][index_id]\n",
    "\n",
    "        trace_y = traces[\"latitude\"][index_id]\n",
    "\n",
    "        shape_id = int(traces[\"shape_id\"][index_id])\n",
    "\n",
    "        candidate_shapes = shapes.loc[shapes['shape_id'] == shape_id]\n",
    "    \n",
    "        trace_coord = (trace_y,trace_x)\n",
    "    \n",
    "        min_distance = 999999999999\n",
    "    \n",
    "        min_shape_sequence = \"\"\n",
    "    \n",
    "        min_shape_coord_lat = 0\n",
    "    \n",
    "        min_shape_coord_lon = 0\n",
    "    \n",
    "        # Compares each possible shape for each record based on line_id of the record in MO file\n",
    "        for _,shape in candidate_shapes.iterrows():\n",
    "            shape_coord = (shape[\"shape_pt_lat\"],shape[\"shape_pt_lon\"])\n",
    "\n",
    "            # distance = geopy.distance.distance(shape_coord,trace_coord).m # lower\n",
    "            distance = haversine(shape_coord,trace_coord,unit=Unit.METERS) # faster using haversine version\n",
    "        \n",
    "            if distance <= min_distance:\n",
    "                min_distance = distance\n",
    "                min_shape_sequence = shape[\"shape_pt_sequence\"]\n",
    "                min_shape_coord_lat = shape[\"shape_pt_lat\"]\n",
    "                min_shape_coord_lon = shape[\"shape_pt_lon\"]\n",
    "        \n",
    "        results.add((dt_avl,id_avl,line_id,trace_y,trace_x,hour_avl,hour_diff,region,time_variation,trip_id,direction,route_id,trip_head,shape_id,min_distance,min_shape_sequence,min_shape_coord_lat,min_shape_coord_lon))\n",
    "\n",
    "    return results\n",
    "\n",
    "# collect the intermediate results in distributed process\n",
    "def collect_result(results):\n",
    "    global results_global\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    df.columns = columns\n",
    "\n",
    "    df.to_parquet(filename+\"-partial-\"+str(len(results)),compression=\"snappy\",index=False)\n",
    "\n",
    "    results_global = results_global + list(results)\n",
    "\n",
    "    print(\"Tamanho do resultado global\",len(results_global))\n",
    "    \n",
    "\n",
    "pool = mp.Pool(machine_cores)\n",
    "\n",
    "# numbers of generated items in each loop\n",
    "amounts = int(outsize/machine_cores)\n",
    "number_of_loops = int(outsize/amounts)\n",
    "residue = outsize - amounts * number_of_loops\n",
    "\n",
    "#first generating residue\n",
    "pool.apply_async(get_shape, args=(residue, 0), callback=collect_result) \n",
    "\n",
    "# generating shippers in  parallel using multiprocessing lib\n",
    "for i in range(number_of_loops):\n",
    "    pool.apply_async(get_shape, args=(amounts, (i * amounts) + residue), callback=collect_result)\n",
    "\n",
    "# closing pool\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "df = pd.DataFrame(results_global)\n",
    "\n",
    "df.columns = columns\n",
    "df.to_parquet(filename+\"-full\",compression=\"snappy\",index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
