{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming AL file with new directions and news columns (route_id and trip_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5debe4a5bcd540e1b5cd3bb468788188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1608251019542_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-86-128.ec2.internal:20888/proxy/application_1608251019542_0001/\" >Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-84-43.ec2.internal:8042/node/containerlogs/container_1608251019542_0001_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark_conf = (SparkConf().set(\"spark.speculation\", \"false\"))\n",
    "sc = SparkContext.getOrCreate(conf = spark_conf)\n",
    "\n",
    "# spark = sparkSession\n",
    "hadoop_conf = spark._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "hadoop_conf.set(\"mapreduce.fileoutputcommitter.algorithm.version\",\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9713a6822e14d1682b790c1e7ac43e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782 2252\n",
      "2782 2252\n",
      "2782 2252\n",
      "2782 2252\n",
      "2782 2252\n",
      "2782 2252\n",
      "2782 2252\n",
      "2782 2252\n",
      "2782 2252\n",
      "2782 2252\n",
      "2782 2252\n",
      "2782 2252\n",
      "2782 2252\n",
      "2782 2252\n",
      "2784 2252\n",
      "2784 2252\n",
      "2784 2252\n",
      "2784 2252\n",
      "2784 2252\n",
      "2784 2252\n",
      "2784 2252\n",
      "2784 2252\n",
      "2784 2252\n",
      "2784 2252\n",
      "2784 2252\n",
      "2784 2252\n",
      "2786 2253\n",
      "2786 2253\n",
      "2784 2252\n",
      "2784 2252\n",
      "2786 2252"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "AL_schema = StructType([\n",
    "    StructField(\"line_number\", StringType()),\n",
    "    StructField(\"complement\", StringType()),\n",
    "    StructField(\"line_id\", IntegerType()),\n",
    "    StructField(\"direction\", IntegerType())\n",
    "])\n",
    "\n",
    "for day in range(1,32):\n",
    "    # Reading AL file\n",
    "    AL = spark.read.csv(\"s3://mobility-traces-sp/aux-files/route-files/AL_1510\"+str(day)+\".txt\",header=False,schema=AL_schema)\n",
    "\n",
    "    trips = spark.read.csv(\"s3://mobility-traces-sp/aux-files/gtfs/trips.csv\",header=True)\n",
    "\n",
    "    trips = trips.drop(\"route_id\",\"service_id\")\n",
    "\n",
    "    # Converting direction 1 to 0, and 2 to 1\n",
    "    AL_new_direction = AL.withColumn(\"new_direction\",when(AL[\"direction\"] == \"1\", 0).otherwise(1))\n",
    "\n",
    "    # dropping new_direction column\n",
    "    AL_direction = AL_new_direction.drop(\"direction\").withColumnRenamed(\"new_direction\",\"direction\")\n",
    "\n",
    "    # Defining route_id and trip_id based in line_number, complement and direction\n",
    "    AL_transformed = AL_direction.withColumn('route_id',concat_ws(\"-\",col(\"line_number\"),col(\"complement\"))) \\\n",
    "        .withColumn('trip_id',concat_ws(\"-\",col(\"route_id\"),(\"direction\")))\n",
    "\n",
    "    # Defining the line_id shape by joining trips.csv and AL file. \n",
    "    # The trips not found in trips.csv are eliminated by inner join\n",
    "    AL_with_shape = AL_transformed.join(trips,on=[\"trip_id\"],how=\"inner\").drop(\"line_number\",\"complement\")\n",
    "    \n",
    "    AL_with_shape.write.parquet(\"s3://mobility-traces-sp/aux-files/route-files-enriched/AL_1510\"+str(day)+\"/\")\n",
    "\n",
    "    print(AL.count(),AL_with_shape.count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
