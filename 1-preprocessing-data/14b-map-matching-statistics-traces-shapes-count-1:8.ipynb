{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d41ee1dd6e4f528a1d5acd9b62473d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1609519824222_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-82-203.ec2.internal:20888/proxy/application_1609519824222_0002/\" >Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-85-137.ec2.internal:8042/node/containerlogs/container_1609519824222_0002_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting more statistics about shapes and traces count for each bus\n",
    "# - exploring the first quantile for working days\n",
    "# - exploring the second quantile for holiday and weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940a5c3e59684950a8a552589fc820aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "Collecting botocore<1.20.0,>=1.19.47 (from boto3)\n",
      "  Using cached https://files.pythonhosted.org/packages/8f/4a/16ffdfc33d93f02604ae9ed1ddb6369030b6f61b583f31dc84e0d0da05c1/botocore-1.19.47-py2.py3-none-any.whl\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0 (from boto3)\n",
      "  Using cached https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl\n",
      "Collecting python-dateutil<3.0.0,>=2.1 (from botocore<1.20.0,>=1.19.47->boto3)\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting urllib3<1.27,>=1.25.4; python_version != \"3.4\" (from botocore<1.20.0,>=1.19.47->boto3)\n",
      "  Using cached https://files.pythonhosted.org/packages/f5/71/45d36a8df68f3ebb098d6861b2c017f3d094538c0fb98fa61d4dc43e69b9/urllib3-1.26.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.47->boto3)\n",
      "Installing collected packages: python-dateutil, urllib3, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.16.47 botocore-1.19.47 python-dateutil-2.8.1 s3transfer-0.3.3 urllib3-1.26.2"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark_conf = (SparkConf().set(\"spark.speculation\", \"false\"))\n",
    "sc = SparkContext.getOrCreate(conf = spark_conf)\n",
    "\n",
    "# spark = sparkSession\n",
    "hadoop_conf = spark._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "hadoop_conf.set(\"mapreduce.fileoutputcommitter.algorithm.version\",\"2\")\n",
    "\n",
    "# installing required packages for this notebook session\n",
    "sc.install_pypi_package(\"boto3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "\n",
    "# files' statistics header\n",
    "csv_out_shape_count = \"day,total_size,shape_seq_count_mean,shape_seq_count_min,shape_seq_count_max,shape_seq_count_stddev,shape_seq_count_quantile_25,shape_seq_count_quantile_50,shape_seq_count_quantile_75\\n\"\n",
    "csv_out_trace_count = \"day,total_size,traces_count_mean,traces_count_min,traces_count_max,traces_count_stddev,traces_count_quantile_25,traces_count_quantile_50,traces_count_quantile_75\\n\"\n",
    "\n",
    "days_second_quantile_50 = set([4,11,12,18,26,17])\n",
    "days_first_quantile_25 = set(range(1,32)) - days_second_quantile_50\n",
    "\n",
    "traces_count_stats  = spark.read.csv(\"s3://mobility-traces-sp/statistics/exploring-data/7-traces_per_bus.csv\",header=True)\n",
    "\n",
    "for day in days_first_quantile_25:\n",
    "    \n",
    "    # reading map matching files\n",
    "    traces = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/8-map-matching/MO_1510\"+ str(day) + \"/\")\n",
    "    \n",
    "    # getting the number of registers\n",
    "    total_size = traces.count()\n",
    "\n",
    "    # counting the number of different shape sequences for a bus in a day\n",
    "    shape_count = traces.groupBy(\"id_avl\",\"line_id\").agg(f.countDistinct(\"min_shape_sequence\").alias(\"shape_seq_count\"))\n",
    "    \n",
    "    # the limits of the first quantile of 25%\n",
    "    shape_count = shape_count.filter(\"shape_seq_count < 101\")\n",
    "\n",
    "    # getting some statistics\n",
    "    stats_shape_seq_count = shape_count.agg(f.mean('shape_seq_count').alias('mean'),\n",
    "                       f.min('shape_seq_count').alias('min'),\n",
    "                       f.max('shape_seq_count').alias('max'),\n",
    "                       f.stddev('shape_seq_count').alias(\"stddev\")).collect()\n",
    "    \n",
    "    # getting the quantiles\n",
    "    shape_seq_count_quantile = shape_count.approxQuantile(\"shape_seq_count\", [0.25,0.5,0.75], 0.0001)\n",
    "    \n",
    "    \n",
    "    csv_out_shape_count += \"MO_1510\" + str(day) +\",\"+ str(total_size) +\",\"+ str(stats_shape_seq_count[0][\"mean\"]) +\",\"+ str(stats_shape_seq_count[0][\"min\"]) + \",\" + str(stats_shape_seq_count[0][\"max\"]) + \",\" + str(stats_shape_seq_count[0][\"stddev\"]) + \",\" +str(shape_seq_count_quantile[0]) + \",\" +str(shape_seq_count_quantile[1]) +\",\" +str(shape_seq_count_quantile[2]) + \"\\n\"\n",
    "\n",
    "\n",
    "import boto3   \n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# writing results in S3\n",
    "s3.put_object(Body=bytes(csv_out_shape_count,\"utf-8\"), Bucket='mobility-traces-sp', Key='statistics/exploring-data/8-shapes_seq_per_bus_25_quantile.csv')\n",
    "\n",
    "\n",
    "for day in range(1,32):\n",
    "    # reading map matching files\n",
    "    traces = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/8-map-matching/MO_1510\"+ str(day) + \"/\")\n",
    "    \n",
    "    # getting the number of registers\n",
    "    total_size = traces.count()\n",
    "    \n",
    "    # counting the number of traces for a bus in a day\n",
    "    trace_count = traces.groupBy(\"id_avl\",\"line_id\").agg(f.count(\"id_avl\").alias(\"traces_count_per_bus\"))\n",
    "    \n",
    "    # limit of the quantile\n",
    "    limit_quantile_25 = traces_count_stats.filter(\"day == 'MO_1510\" + str(day)+\"'\").collect()[0][\"traces_count_quantile_25\"]\n",
    "\n",
    "    trace_count = trace_count.filter(\"traces_count_per_bus < \" + str(limit_quantile_25))\n",
    "    \n",
    "    # getting some statistics\n",
    "    stats_trace_count = trace_count.agg(f.mean('traces_count_per_bus').alias('mean'),\n",
    "                       f.min('traces_count_per_bus').alias('min'),\n",
    "                       f.max('traces_count_per_bus').alias('max'),\n",
    "                       f.stddev('traces_count_per_bus').alias(\"stddev\")).collect()\n",
    "    \n",
    "    # getting the quantiles\n",
    "    trace_count_quantile = trace_count.approxQuantile(\"traces_count_per_bus\", [0.25,0.5,0.75], 0.0001)\n",
    "    \n",
    "    csv_out_trace_count += \"MO_1510\" + str(day) +\",\"+ str(total_size) +\",\"+ str(stats_trace_count[0][\"mean\"]) +\",\"+ str(stats_trace_count[0][\"min\"]) + \",\" + str(stats_trace_count[0][\"max\"]) + \",\" + str(stats_trace_count[0][\"stddev\"]) + \",\" +str(trace_count_quantile[0]) + \",\" +str(trace_count_quantile[1]) +\",\" +str(trace_count_quantile[2]) +\"\\n\"\n",
    "\n",
    "    \n",
    "s3.put_object(Body=bytes(csv_out_trace_count,\"utf-8\"), Bucket='mobility-traces-sp', Key='statistics/exploring-data/7-traces_per_bus_25_quantile.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_count_stats  = spark.read.csv(\"s3://mobility-traces-sp/statistics/exploring-data/7-traces_per_bus_25_quantile.csv\",header=True)\n",
    "csv_out_trace_count = \"day,total_size,traces_count_mean,traces_count_min,traces_count_max,traces_count_stddev,traces_count_quantile_25,traces_count_quantile_50,traces_count_quantile_75\\n\"\n",
    "\n",
    "for day in range(1,32):\n",
    "    # reading map matching files\n",
    "    traces = spark.read.parquet(\"s3://mobility-traces-sp/processed-data-avl-date/8-map-matching/MO_1510\"+ str(day) + \"/\")\n",
    "    \n",
    "    # getting the number of registers\n",
    "    total_size = traces.count()\n",
    "    \n",
    "    # counting the number of traces for a bus in a day\n",
    "    trace_count = traces.groupBy(\"id_avl\",\"line_id\").agg(f.count(\"id_avl\").alias(\"traces_count_per_bus\"))\n",
    "    \n",
    "    # limit of the quantile\n",
    "    limit_quantile_25 = traces_count_stats.filter(\"day == 'MO_1510\" + str(day)+\"'\").collect()[0][\"traces_count_quantile_25\"]\n",
    "    trace_count = trace_count.filter(\"traces_count_per_bus < \" + str(limit_quantile_25))\n",
    "    # getting some statistics\n",
    "    stats_trace_count = trace_count.agg(f.mean('traces_count_per_bus').alias('mean'),\n",
    "                       f.min('traces_count_per_bus').alias('min'),\n",
    "                       f.max('traces_count_per_bus').alias('max'),\n",
    "                       f.stddev('traces_count_per_bus').alias(\"stddev\")).collect()\n",
    "    # getting the quantiles\n",
    "    trace_count_quantile = trace_count.approxQuantile(\"traces_count_per_bus\", [0.25,0.5,0.75], 0.0001)\n",
    "    trace_count_quantile\n",
    "    csv_out_trace_count += \"MO_1510\" + str(day) +\",\"+ str(total_size) +\",\"+ str(stats_trace_count[0][\"mean\"]) +\",\"+ str(stats_trace_count[0][\"min\"]) + \",\" + str(stats_trace_count[0][\"max\"]) + \",\" + str(stats_trace_count[0][\"stddev\"]) + \",\" +str(trace_count_quantile[0]) + \",\" +str(trace_count_quantile[1]) +\",\" +str(trace_count_quantile[2]) +\"\\n\"\n",
    "\n",
    "    \n",
    "s3.put_object(Body=bytes(csv_out_trace_count,\"utf-8\"), Bucket='mobility-traces-sp', Key='statistics/exploring-data/7-traces_per_bus_25_quantile_2_times.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
